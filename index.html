<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/course-showcase/_next/static/media/569ce4b8f30dc480-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/course-showcase/_next/static/media/93f479601ee12b01-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/course-showcase/pic/pipeline.png"/><link rel="preload" as="image" href="/course-showcase/pic/yoloPipeline.png"/><link rel="preload" as="image" href="/course-showcase/pic/out_1736.png"/><link rel="preload" as="image" href="/course-showcase/pic/out_1736_sketch.png"/><link rel="preload" as="image" href="/course-showcase/pic/out_1736_3.png"/><link rel="preload" as="image" href="/course-showcase/pic/Screenshot294.png"/><link rel="preload" as="image" href="/course-showcase/pic/294_sketch.png"/><link rel="preload" as="image" href="/course-showcase/pic/294.png"/><link rel="preload" as="image" href="/course-showcase/pic/box_1736.png"/><link rel="preload" as="image" href="/course-showcase/pic/1736_sketch_box.png"/><link rel="stylesheet" href="/course-showcase/_next/static/css/7a019d74a9400602.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/course-showcase/_next/static/chunks/webpack-6724b22777434855.js"/><script src="/course-showcase/_next/static/chunks/4bd1b696-92810b4b4ece63ad.js" async=""></script><script src="/course-showcase/_next/static/chunks/517-444e66b5189ec689.js" async=""></script><script src="/course-showcase/_next/static/chunks/main-app-1dbe18473b3fc40c.js" async=""></script><link rel="preload" as="image" href="/course-showcase/pic/1736_box.png"/><link rel="preload" as="image" href="/course-showcase/pic/holofin1.jpg"/><link rel="preload" as="image" href="/course-showcase/pic/holofin2.jpg"/><link rel="preload" as="image" href="/course-showcase/pic/holofin3.jpg"/><link rel="preload" as="image" href="/course-showcase/pic/000128_Client0_rawImage_gim_dkm_match.png"/><link rel="preload" as="image" href="/course-showcase/pic/000128_Client1_rawImage_gim_dkm_match.png"/><link rel="preload" as="image" href="/course-showcase/pic/000128_Client0_rawImage_gim_dkm_warp.png"/><link rel="preload" as="image" href="/course-showcase/pic/000128_Client1_rawImage_gim_dkm_warp.png"/><meta name="next-size-adjust" content=""/><title>Improving Object Pose Estimation with Line Features in Mixed Reality</title><meta name="description" content="Generated by create next app"/><link rel="icon" href="/course-showcase/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/course-showcase/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_bb75c6 __variable_237161 antialiased"><main class="bg-white min-h-screen flex flex-col items-center justify-center"><div class="w-full max-w-6xl px-4 mx-auto my-8"><h1 class="text-4xl font-bold text-blue-600 pt-10 text-center">Improving Object Pose Estimation with Line Features in Mixed Reality</h1><p class="text-lg text-gray-700 mt-4 text-center">ETHz Mixed Reality 2024</p><div class="mt-6 flex flex-wrap justify-center space-x-4"><div class="text-lg text-gray-700">Deqing Song</div><div class="text-lg text-gray-700">Moyang Li</div><div class="text-lg text-gray-700">Yifan Jiang</div><div class="text-lg text-gray-700">Yuqiao Huang</div></div><div class="mt-6 flex justify-center"><a href="https://github.com/DavidSong2000/SBBTrainDoorLocolization" target="_blank" class="inline-block text-sm text-white bg-blue-600 px-4 py-2 rounded-lg hover:bg-blue-500 text-center"><span><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" class="svg-inline--fa fa-github text-white text-xl text-center" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>Code</span></a></div><div class="mt-8 w-full px-6 py-4"><h2 class="text-3xl font-bold text-gray-800 text-center">Project Overview</h2><p class="text-lg text-gray-700 mt-4 max-w-full text-left">This project explores the potential of using line features to improve object pose estimation in mixed reality for SBB doors. Using real-time image sequences from the HoloLens, we conducted experiments to accurately match a query image with existing features with high precision. We compared LiMAP and GIM as feature matching methods, evaluating their performance in complex environments. Our findings indicate that while line features, even after image filtering, demonstrate potential, they are still outperformed by GIM, which provides a more efficient solution for real-time feature matching of SBB doors in mixed reality applications.</p></div><div class="mt-8 w-full px-6 py-4"><h2 class="text-3xl font-bold text-gray-800 text-center">Pipeline</h2><p class="text-lg text-gray-700 mt-4 max-w-full text-left">LiMAP is a line-based feature matching algorithm that uses line segments extracted from images to estimate object poses. The algorithm first detects line segments in the reference and query images, then matches them based on their geometric properties. By calculating the transformation matrix between the two images, LiMAP accurately localizes the object in the query image.</p><p class="text-lg text-gray-700 mt-4 max-w-full text-left">GIM (Generalizable Image Matcher) is a self-supervised framework designed to learn robust image matching models with strong generalization capabilities from internet videos. By leveraging candidate correspondences between adjacent frames and propagating them to wider baselines, GIM enhances the training process for improved performance in unseen scenarios. In our project, we use GIM to localize SBB car doors, utilizing its ability to extract reliable feature correspondences.</p><p class="text-lg text-gray-700 mt-4 max-w-full text-left">In this project, we compare the performance of LiMAP and GIM in feature matching accuracy, evaluating their robustness in further localization of SBB train doors.</p><div class="flex justify-center w-full"><img src="/course-showcase/pic/pipeline.png" alt="LiMAP" class="flex-1 rounded-lg"/></div></div><div class="mt-8 w-full px-6 py-4"><h2 class="text-3xl font-bold text-gray-800 text-center">YOLO Object Detection</h2><p class="text-lg text-gray-700 mt-4 max-w-full text-left">In our project, we use YOLO Bouding Box to detect SBB train doors in the image sequences captured by the HoloLens. By identifying the doors in the images, we can extract the region of interest for further processing.</p><div class="flex justify-center w-full"><img src="/course-showcase/pic/yoloPipeline.png" alt="YOLO" class="flex-1 rounded-lg"/></div></div><div class="mt-8 w-full px-6 py-4"><h2 class="text-3xl font-bold text-gray-800 text-center">LiMAP Results</h2><p class="text-lg text-gray-700 mt-4 max-w-full text-left">Our experiments demonstrate that LiMAP is effective in reconstructing SBB train doors.</p><p class="text-lg text-gray-700 mt-4 max-w-full text-left">Our experiments reveal that LiMAP with bounding boxes is still insufficient for accurately localizing SBB train doors with high precision. While the algorithm successfully reconstructs the line features of the SBB train doors, it struggles to transfer the learned features from the synthetic dataset to real-world query images, regardless of whether bounding boxes are applied.</p><h3 class="text-2xl font-bold text-gray-800 text-center py-5">SBB train door reconstruction using LiMAP</h3><div class="flex flex-wrap justify-between w-full max-w-1xl space-y-4"><div class=" w-full space-x-4"><video autoPlay="" loop="" muted="" playsInline="" src="/course-showcase/videos/web_limap_reconstruction.mp4" class="flex-1">Your browser does not support the video tag.</video></div><div class="w-full space-x-4"><video autoPlay="" loop="" muted="" playsInline="" src="/course-showcase/videos/web_limapD.mp4" class="w-full">Your browser does not support the video tag.</video></div></div><h3 class="text-2xl font-bold text-gray-800 text-center py-5">LiMAP 2D-3D Line Matching Results</h3><h4 class="text-xl font-bold text-gray-800 text-left py-5">2D-3D Line Matching <span class="text-red-600">Without</span> <!-- -->Bounding Box</h4><div class="flex justify-center w-full"><img src="/course-showcase/pic/out_1736.png" alt="LiMAP" class="w-1/3 mr-1 "/><img src="/course-showcase/pic/out_1736_sketch.png" alt="LiMAP" class="w-1/3 mr-1"/><img src="/course-showcase/pic/out_1736_3.png" alt="LiMAP" class="w-1/3 "/></div><h4 class="text-xl font-bold text-gray-800 text-left py-5">2D-3D Line Matching <span class="text-red-600">Without</span> <!-- -->Bounding Box<!-- --> <span class="text-yellow-600">in Synthetic Image</span></h4><div class="flex justify-center w-full"><img src="/course-showcase/pic/Screenshot294.png" alt="LiMAP" class="w-1/3 mr-1 "/><img src="/course-showcase/pic/294_sketch.png" alt="LiMAP" class="w-1/3 mr-1"/><img src="/course-showcase/pic/294.png" alt="LiMAP" class="w-1/3 "/></div><h4 class="text-xl font-bold text-gray-800 text-left py-5 mt-5">2D-3D Line Matching <span class="text-red-600">With</span> <!-- -->Bounding Box</h4><div class="flex justify-center w-full"><img src="/course-showcase/pic/box_1736.png" alt="LiMAP" class="w-1/3 mr-1 "/><img src="/course-showcase/pic/1736_sketch_box.png" alt="LiMAP" class="w-1/3 mr-1"/><img src="/course-showcase/pic/1736_box.png" alt="LiMAP" class="w-1/3 "/></div></div><div class="mt-8 w-full px-6 py-4"><h2 class="text-3xl font-bold text-gray-800 text-center">GIM Results</h2><p class="text-lg text-gray-700 mt-4 max-w-full text-left">Our experiments show that GIM outperforms well in feature matching accuracy. The GIM algorithm is robust to occlusion and cluttered backgrounds, providing a more reliable solution for further object pose estimation in mixed reality applications.</p><div class="flex flex-wrap justify-between w-full max-w-1xl space-y-4 mt-7"><div class="flex justify-between w-full space-x-4"><video autoPlay="" loop="" muted="" playsInline="" class="w-1/2" src="/course-showcase/videos/web_match1.mp4">Your browser does not support the video tag.</video><video autoPlay="" loop="" muted="" playsInline="" class="w-1/2" src="/course-showcase/videos/web_match2.mp4">Your browser does not support the video tag.</video></div><div class="flex justify-between w-full space-x-4"><video autoPlay="" loop="" muted="" playsInline="" src="/course-showcase/videos/web_warp1.mp4">Your browser does not support the video tag.</video></div><div class="flex justify-between w-full space-x-4"><video autoPlay="" loop="" muted="" playsInline="" src="/course-showcase/videos/web_warp2.mp4">Your browser does not support the video tag.</video></div></div></div><div class="mt-8 w-full px-6 py-4"><h2 class="text-3xl font-bold text-gray-800 text-center">Hololens Implementation</h2><p class="text-lg text-gray-700 mt-4 max-w-full text-left">We implemented the GIM algorithms on the HoloLens. By leveraging the HoloLens capabilities, we accurately localize SBB train doors in mixed reality environments, providing a reliable solution for applications in the transportation industry.</p><h4 class="text-xl font-bold text-gray-800 text-left py-5">Hololens real-time implementation</h4><div class="flex justify-center w-full"><img src="/course-showcase/pic/holofin1.jpg" alt="project overview" class="w-1/3"/><img src="/course-showcase/pic/holofin2.jpg" alt="project overview" class="w-1/3"/><img src="/course-showcase/pic/holofin3.jpg" alt="project overview" class="w-1/3"/></div><div class="flex justify-center w-full mt-5"><img src="/course-showcase/pic/000128_Client0_rawImage_gim_dkm_match.png" alt="project overview" class="w-1/2"/><img src="/course-showcase/pic/000128_Client1_rawImage_gim_dkm_match.png" alt="project overview" class="w-1/2"/></div><div class="flex justify-center w-full mt-5"><img src="/course-showcase/pic/000128_Client0_rawImage_gim_dkm_warp.png" alt="project overview" class="flex-1"/></div><div class="flex justify-center w-full"><img src="/course-showcase/pic/000128_Client1_rawImage_gim_dkm_warp.png" alt="project overview" class="flex-1"/></div></div></div></main><script src="/course-showcase/_next/static/chunks/webpack-6724b22777434855.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[5244,[],\"\"]\n3:I[3866,[],\"\"]\n5:I[6213,[],\"OutletBoundary\"]\n7:I[6213,[],\"MetadataBoundary\"]\n9:I[6213,[],\"ViewportBoundary\"]\nb:I[4835,[],\"\"]\n:HL[\"/course-showcase/_next/static/media/569ce4b8f30dc480-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/course-showcase/_next/static/media/93f479601ee12b01-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/course-showcase/_next/static/css/7a019d74a9400602.css\",\"style\"]\n4:T518,M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"_G_sABuKeo2iS0fPfAcle\",\"p\":\"/course-showcase\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/course-showcase/_next/static/css/7a019d74a9400602.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__variable_bb75c6 __variable_237161 antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"main\",null,{\"className\":\"bg-white min-h-screen flex flex-col items-center justify-center\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-full max-w-6xl px-4 mx-auto my-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold text-blue-600 pt-10 text-center\",\"children\":\"Improving Object Pose Estimation with Line Features in Mixed Reality\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-gray-700 mt-4 text-center\",\"children\":\"ETHz Mixed Reality 2024\"}],[\"$\",\"div\",null,{\"className\":\"mt-6 flex flex-wrap justify-center space-x-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-lg text-gray-700\",\"children\":\"Deqing Song\"}],[\"$\",\"div\",null,{\"className\":\"text-lg text-gray-700\",\"children\":\"Moyang Li\"}],[\"$\",\"div\",null,{\"className\":\"text-lg text-gray-700\",\"children\":\"Yifan Jiang\"}],[\"$\",\"div\",null,{\"className\":\"text-lg text-gray-700\",\"children\":\"Yuqiao Huang\"}]]}],[\"$\",\"div\",null,{\"className\":\"mt-6 flex justify-center\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://github.com/DavidSong2000/SBBTrainDoorLocolization\",\"target\":\"_blank\",\"className\":\"inline-block text-sm text-white bg-blue-600 px-4 py-2 rounded-lg hover:bg-blue-500 text-center\",\"children\":[\"$\",\"span\",null,{\"children\":[[\"$\",\"svg\",null,{\"aria-hidden\":\"true\",\"focusable\":\"false\",\"data-prefix\":\"fab\",\"data-icon\":\"github\",\"className\":\"svg-inline--fa fa-github text-white text-xl text-center\",\"role\":\"img\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"viewBox\":\"0 0 496 512\",\"style\":{},\"ref\":\"$undefined\",\"children\":[\"$\",\"path\",null,{\"fill\":\"currentColor\",\"d\":\"$4\",\"style\":{}}]}],\"Code\"]}]}]}],[\"$\",\"div\",null,{\"className\":\"mt-8 w-full px-6 py-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-800 text-center\",\"children\":\"Project Overview\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-gray-700 mt-4 max-w-full text-left\",\"children\":\"This project explores the potential of using line features to improve object pose estimation in mixed reality for SBB doors. Using real-time image sequences from the HoloLens, we conducted experiments to accurately match a query image with existing features with high precision. We compared LiMAP and GIM as feature matching methods, evaluating their performance in complex environments. Our findings indicate that while line features, even after image filtering, demonstrate potential, they are still outperformed by GIM, which provides a more efficient solution for real-time feature matching of SBB doors in mixed reality applications.\"}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8 w-full px-6 py-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-800 text-center\",\"children\":\"Pipeline\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-gray-700 mt-4 max-w-full text-left\",\"children\":\"LiMAP is a line-based feature matching algorithm that uses line segments extracted from images to estimate object poses. The algorithm first detects line segments in the reference and query images, then matches them based on their geometric properties. By calculating the transformation matrix between the two images, LiMAP accurately localizes the object in the query image.\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-gray-700 mt-4 max-w-full text-left\",\"children\":\"GIM (Generalizable Image Matcher) is a self-supervised framework designed to learn robust image matching models with strong generalization capabilities from internet videos. By leveraging candidate correspondences between adjacent frames and propagating them to wider baselines, GIM enhances the training process for improved performance in unseen scenarios. In our project, we use GIM to localize SBB car doors, utilizing its ability to extract reliable feature correspondences.\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-gray-700 mt-4 max-w-full text-left\",\"children\":\"In this project, we compare the performance of LiMAP and GIM in feature matching accuracy, evaluating their robustness in further localization of SBB train doors.\"}],[\"$\",\"div\",null,{\"className\":\"flex justify-center w-full\",\"children\":[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/pipeline.png\",\"alt\":\"LiMAP\",\"className\":\"flex-1 rounded-lg\"}]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8 w-full px-6 py-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-800 text-center\",\"children\":\"YOLO Object Detection\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-gray-700 mt-4 max-w-full text-left\",\"children\":\"In our project, we use YOLO Bouding Box to detect SBB train doors in the image sequences captured by the HoloLens. By identifying the doors in the images, we can extract the region of interest for further processing.\"}],[\"$\",\"div\",null,{\"className\":\"flex justify-center w-full\",\"children\":[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/yoloPipeline.png\",\"alt\":\"YOLO\",\"className\":\"flex-1 rounded-lg\"}]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8 w-full px-6 py-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-800 text-center\",\"children\":\"LiMAP Results\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-gray-700 mt-4 max-w-full text-left\",\"children\":\"Our experiments demonstrate that LiMAP is effective in reconstructing SBB train doors.\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-gray-700 mt-4 max-w-full text-left\",\"children\":\"Our experiments reveal that LiMAP with bounding boxes is still insufficient for accurately localizing SBB train doors with high precision. While the algorithm successfully reconstructs the line features of the SBB train doors, it struggles to transfer the learned features from the synthetic dataset to real-world query images, regardless of whether bounding boxes are applied.\"}],[\"$\",\"h3\",null,{\"className\":\"text-2xl font-bold text-gray-800 text-center py-5\",\"children\":\"SBB train door reconstruction using LiMAP\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap justify-between w-full max-w-1xl space-y-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\" w-full space-x-4\",\"children\":[\"$\",\"video\",null,{\"autoPlay\":true,\"loop\":true,\"muted\":true,\"playsInline\":true,\"src\":\"/course-showcase/videos/web_limap_reconstruction.mp4\",\"className\":\"flex-1\",\"children\":\"Your browser does not support the video tag.\"}]}],[\"$\",\"div\",null,{\"className\":\"w-full space-x-4\",\"children\":[\"$\",\"video\",null,{\"autoPlay\":true,\"loop\":true,\"muted\":true,\"playsInline\":true,\"src\":\"/course-showcase/videos/web_limapD.mp4\",\"className\":\"w-full\",\"children\":\"Your browser does not support the video tag.\"}]}]]}],[\"$\",\"h3\",null,{\"className\":\"text-2xl font-bold text-gray-800 text-center py-5\",\"children\":\"LiMAP 2D-3D Line Matching Results\"}],[\"$\",\"h4\",null,{\"className\":\"text-xl font-bold text-gray-800 text-left py-5\",\"children\":[\"2D-3D Line Matching \",[\"$\",\"span\",null,{\"className\":\"text-red-600\",\"children\":\"Without\"}],\" \",\"Bounding Box\"]}],[\"$\",\"div\",null,{\"className\":\"flex justify-center w-full\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/out_1736.png\",\"alt\":\"LiMAP\",\"className\":\"w-1/3 mr-1 \"}],[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/out_1736_sketch.png\",\"alt\":\"LiMAP\",\"className\":\"w-1/3 mr-1\"}],[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/out_1736_3.png\",\"alt\":\"LiMAP\",\"className\":\"w-1/3 \"}]]}],[\"$\",\"h4\",null,{\"className\":\"text-xl font-bold text-gray-800 text-left py-5\",\"children\":[\"2D-3D Line Matching \",[\"$\",\"span\",null,{\"className\":\"text-red-600\",\"children\":\"Without\"}],\" \",\"Bounding Box\",\" \",[\"$\",\"span\",null,{\"className\":\"text-yellow-600\",\"children\":\"in Synthetic Image\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex justify-center w-full\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/Screenshot294.png\",\"alt\":\"LiMAP\",\"className\":\"w-1/3 mr-1 \"}],[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/294_sketch.png\",\"alt\":\"LiMAP\",\"className\":\"w-1/3 mr-1\"}],[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/294.png\",\"alt\":\"LiMAP\",\"className\":\"w-1/3 \"}]]}],[\"$\",\"h4\",null,{\"className\":\"text-xl font-bold text-gray-800 text-left py-5 mt-5\",\"children\":[\"2D-3D Line Matching \",[\"$\",\"span\",null,{\"className\":\"text-red-600\",\"children\":\"With\"}],\" \",\"Bounding Box\"]}],[\"$\",\"div\",null,{\"className\":\"flex justify-center w-full\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/box_1736.png\",\"alt\":\"LiMAP\",\"className\":\"w-1/3 mr-1 \"}],[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/1736_sketch_box.png\",\"alt\":\"LiMAP\",\"className\":\"w-1/3 mr-1\"}],[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/1736_box.png\",\"alt\":\"LiMAP\",\"className\":\"w-1/3 \"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8 w-full px-6 py-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-800 text-center\",\"children\":\"GIM Results\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-gray-700 mt-4 max-w-full text-left\",\"children\":\"Our experiments show that GIM outperforms well in feature matching accuracy. The GIM algorithm is robust to occlusion and cluttered backgrounds, providing a more reliable solution for further object pose estimation in mixed reality applications.\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap justify-between w-full max-w-1xl space-y-4 mt-7\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex justify-between w-full space-x-4\",\"children\":[[\"$\",\"video\",null,{\"autoPlay\":true,\"loop\":true,\"muted\":true,\"playsInline\":true,\"className\":\"w-1/2\",\"src\":\"/course-showcase/videos/web_match1.mp4\",\"children\":\"Your browser does not support the video tag.\"}],[\"$\",\"video\",null,{\"autoPlay\":true,\"loop\":true,\"muted\":true,\"playsInline\":true,\"className\":\"w-1/2\",\"src\":\"/course-showcase/videos/web_match2.mp4\",\"children\":\"Your browser does not support the video tag.\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex justify-between w-full space-x-4\",\"children\":[\"$\",\"video\",null,{\"autoPlay\":true,\"loop\":true,\"muted\":true,\"playsInline\":true,\"src\":\"/course-showcase/videos/web_warp1.mp4\",\"children\":\"Your browser does not support the video tag.\"}]}],[\"$\",\"div\",null,{\"className\":\"flex justify-between w-full space-x-4\",\"children\":[\"$\",\"video\",null,{\"autoPlay\":true,\"loop\":true,\"muted\":true,\"playsInline\":true,\"src\":\"/course-showcase/videos/web_warp2.mp4\",\"children\":\"Your browser does not support the video tag.\"}]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8 w-full px-6 py-4\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-800 text-center\",\"children\":\"Hololens Implementation\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-gray-700 mt-4 max-w-full text-left\",\"children\":\"We implemented the GIM algorithms on the HoloLens. By leveraging the HoloLens capabilities, we accurately localize SBB train doors in mixed reality environments, providing a reliable solution for applications in the transportation industry.\"}],[\"$\",\"h4\",null,{\"className\":\"text-xl font-bold text-gray-800 text-left py-5\",\"children\":\"Hololens real-time implementation\"}],[\"$\",\"div\",null,{\"className\":\"flex justify-center w-full\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/holofin1.jpg\",\"alt\":\"project overview\",\"className\":\"w-1/3\"}],[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/holofin2.jpg\",\"alt\":\"project overview\",\"className\":\"w-1/3\"}],[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/holofin3.jpg\",\"alt\":\"project overview\",\"className\":\"w-1/3\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex justify-center w-full mt-5\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/000128_Client0_rawImage_gim_dkm_match.png\",\"alt\":\"project overview\",\"className\":\"w-1/2\"}],[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/000128_Client1_rawImage_gim_dkm_match.png\",\"alt\":\"project overview\",\"className\":\"w-1/2\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex justify-center w-full mt-5\",\"children\":[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/000128_Client0_rawImage_gim_dkm_warp.png\",\"alt\":\"project overview\",\"className\":\"flex-1\"}]}],[\"$\",\"div\",null,{\"className\":\"flex justify-center w-full\",\"children\":[\"$\",\"img\",null,{\"src\":\"/course-showcase/pic/000128_Client1_rawImage_gim_dkm_warp.png\",\"alt\":\"project overview\",\"className\":\"flex-1\"}]}]]}]]}]}],null,[\"$\",\"$L5\",null,{\"children\":\"$L6\"}]]}],{},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"g7eTU1pTCkD6hI7ASWQ02\",{\"children\":[[\"$\",\"$L7\",null,{\"children\":\"$L8\"}],[\"$\",\"$L9\",null,{\"children\":\"$La\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$b\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n8:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Improving Object Pose Estimation with Line Features in Mixed Reality\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"Generated by create next app\"}],[\"$\",\"link\",\"3\",{\"rel\":\"icon\",\"href\":\"/course-showcase/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"6:null\n"])</script></body></html>